{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = pd.read_csv('./data/Augmented_Data2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Command</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Identifier</th>\n",
       "      <th>Action</th>\n",
       "      <th>One Hot Encoded Topic</th>\n",
       "      <th>One Hot Encoded Action</th>\n",
       "      <th>Verb/Noun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>finish plan Developing editorial calendar for ...</td>\n",
       "      <td>Project</td>\n",
       "      <td>Developing editorial calendar for content sharing</td>\n",
       "      <td>Completed</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>[0,0,0,0,1]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>move plan Developing editorial calendar for co...</td>\n",
       "      <td>Project</td>\n",
       "      <td>Developing editorial calendar for content sharing</td>\n",
       "      <td>At Risk</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>[0,0,1,0,0]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fixed Developing editorial calendar for conten...</td>\n",
       "      <td>Task</td>\n",
       "      <td>Developing editorial calendar for content sharing</td>\n",
       "      <td>In Review</td>\n",
       "      <td>[1,0]</td>\n",
       "      <td>[0,0,1,0,0]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>audit task Developing editorial calendar for c...</td>\n",
       "      <td>Task</td>\n",
       "      <td>Developing editorial calendar for content sharing</td>\n",
       "      <td>In Review</td>\n",
       "      <td>[1,0]</td>\n",
       "      <td>[0,0,1,0,0]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>offset on Developing editorial calendar for co...</td>\n",
       "      <td>Task</td>\n",
       "      <td>Developing editorial calendar for content sharing</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>[1,0]</td>\n",
       "      <td>[0,1,0,0,0]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6974</th>\n",
       "      <td>end throw Reviewing website backlinks</td>\n",
       "      <td>Project</td>\n",
       "      <td>Reviewing website backlinks</td>\n",
       "      <td>Completed</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>[0,0,0,0,1]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6975</th>\n",
       "      <td>to do Reviewing website backlinks plan</td>\n",
       "      <td>Project</td>\n",
       "      <td>Reviewing website backlinks</td>\n",
       "      <td>Create</td>\n",
       "      <td>[0,1]</td>\n",
       "      <td>[1,0,0,0,0]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6976</th>\n",
       "      <td>Reviewing website backlinks project</td>\n",
       "      <td>Task</td>\n",
       "      <td>Reviewing website backlinks</td>\n",
       "      <td>To Do</td>\n",
       "      <td>[1,0]</td>\n",
       "      <td>[1,0,0,0,0]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6977</th>\n",
       "      <td>Reviewing website backlinks chore was complete</td>\n",
       "      <td>Task</td>\n",
       "      <td>Reviewing website backlinks</td>\n",
       "      <td>Completed</td>\n",
       "      <td>[1,0]</td>\n",
       "      <td>[0,0,0,0,1]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6978</th>\n",
       "      <td>through with task Reviewing website backlinks</td>\n",
       "      <td>Task</td>\n",
       "      <td>Reviewing website backlinks</td>\n",
       "      <td>Completed</td>\n",
       "      <td>[1,0]</td>\n",
       "      <td>[0,0,0,0,1]</td>\n",
       "      <td>SYNREPLACED</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6979 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Text Command    Topic  \\\n",
       "0     finish plan Developing editorial calendar for ...  Project   \n",
       "1     move plan Developing editorial calendar for co...  Project   \n",
       "2     fixed Developing editorial calendar for conten...     Task   \n",
       "3     audit task Developing editorial calendar for c...     Task   \n",
       "4     offset on Developing editorial calendar for co...     Task   \n",
       "...                                                 ...      ...   \n",
       "6974              end throw Reviewing website backlinks  Project   \n",
       "6975             to do Reviewing website backlinks plan  Project   \n",
       "6976                Reviewing website backlinks project     Task   \n",
       "6977     Reviewing website backlinks chore was complete     Task   \n",
       "6978      through with task Reviewing website backlinks     Task   \n",
       "\n",
       "                                             Identifier       Action  \\\n",
       "0     Developing editorial calendar for content sharing    Completed   \n",
       "1     Developing editorial calendar for content sharing      At Risk   \n",
       "2     Developing editorial calendar for content sharing    In Review   \n",
       "3     Developing editorial calendar for content sharing    In Review   \n",
       "4     Developing editorial calendar for content sharing  In Progress   \n",
       "...                                                 ...          ...   \n",
       "6974                        Reviewing website backlinks    Completed   \n",
       "6975                        Reviewing website backlinks       Create   \n",
       "6976                        Reviewing website backlinks        To Do   \n",
       "6977                        Reviewing website backlinks    Completed   \n",
       "6978                        Reviewing website backlinks    Completed   \n",
       "\n",
       "     One Hot Encoded Topic One Hot Encoded Action    Verb/Noun  \n",
       "0                    [0,1]            [0,0,0,0,1]  SYNREPLACED  \n",
       "1                    [0,1]            [0,0,1,0,0]  SYNREPLACED  \n",
       "2                    [1,0]            [0,0,1,0,0]  SYNREPLACED  \n",
       "3                    [1,0]            [0,0,1,0,0]  SYNREPLACED  \n",
       "4                    [1,0]            [0,1,0,0,0]  SYNREPLACED  \n",
       "...                    ...                    ...          ...  \n",
       "6974                 [0,1]            [0,0,0,0,1]  SYNREPLACED  \n",
       "6975                 [0,1]            [1,0,0,0,0]  SYNREPLACED  \n",
       "6976                 [1,0]            [1,0,0,0,0]  SYNREPLACED  \n",
       "6977                 [1,0]            [0,0,0,0,1]  SYNREPLACED  \n",
       "6978                 [1,0]            [0,0,0,0,1]  SYNREPLACED  \n",
       "\n",
       "[6979 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes(object):\n",
    "    #initialize model\n",
    "    def __init__(self,data,training_split,use_case,laplace):\n",
    "        self.use_case = use_case\n",
    "        if self.use_case == 'topic':\n",
    "            self.columns = ['Text Command', 'Topic']\n",
    "        else:\n",
    "            self.columns = ['Text Command','Action']\n",
    "            if self.use_case == 'task action':\n",
    "                data = data[data['Topic'] == 'Task']\n",
    "            else:\n",
    "                data = data[data['Topic'] == 'Project']\n",
    "        self.num_rows = len(data)\n",
    "        #shuffle data and reset indexes\n",
    "        self.shuffled_data = data.sample(frac=1).reset_index(drop=True)\n",
    "        #split the data into training and testing sets using input proportion \n",
    "        (self.training_data,self.testing_data) = self.training_testing_split(self.shuffled_data,training_split)\n",
    "        self.num_training_rows,self.num_testing_rows = len(self.training_data),len(self.testing_data)\n",
    "        self.smoothing_constant = laplace\n",
    "        if self.use_case == 'topic':\n",
    "            index_action = {'Task':0, 'Project':1}\n",
    "        if self.use_case == 'task action':\n",
    "            index_action = {'To Do': 0, 'In Progress':1, 'In Review':2, 'Blocked':3, 'Completed':4}\n",
    "        if self.use_case == 'project action':\n",
    "            index_action = {'Create':0, 'On Target':1, 'At Risk':2, 'Danger':3, 'Completed':4}\n",
    "        self.index_action = index_action\n",
    "        self.label_map = dict()\n",
    "        for key in self.index_action:\n",
    "            self.label_map[self.index_action[key]] = key\n",
    "            \n",
    "        \n",
    "    def training_testing_split(self,all_data,training_split):\n",
    "        \n",
    "        breakoff = int(self.num_rows*training_split)\n",
    "        return (all_data.loc[:breakoff],all_data[self.columns].loc[breakoff:])\n",
    "    \n",
    "    #words to ignore when calculating probabilities\n",
    "    def stopwords(self):\n",
    "        return [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]\n",
    "\n",
    "    def compute_probabilities(self,text_command_training_data):\n",
    "        action_map = self.label_map\n",
    "        action_probabilities = dict()\n",
    "        action_dict = dict()\n",
    "        word_dict = dict()\n",
    "        word_counter = 0\n",
    "        stopwords = self.stopwords()\n",
    "        for action in list(action_map.values()):\n",
    "            action_dict[action] = dict()\n",
    "        for i in list(text_command_training_data.index.values):\n",
    "            action = text_command_training_data.loc[i][1]\n",
    "            action_probabilities[action] = action_probabilities.get(action,0) + 1\n",
    "            text_command = text_command_training_data.loc[i][0]\n",
    "            for word in text_command.lower().split():\n",
    "                if word not in stopwords:\n",
    "                    word_counter += 1\n",
    "                    word_dict[word] = word_dict.get(word,0) + 1\n",
    "                    action_dict[action][word] = action_dict[action].get(word,0) + 1\n",
    "        num_unique_words = len(word_dict)\n",
    "        for action in action_dict:\n",
    "            num_words = sum(list(action_dict[action].values()))\n",
    "            for word in action_dict[action]:\n",
    "                action_dict[action][word] = (action_dict[action][word]+self.smoothing_constant)/(num_words+self.smoothing_constant*num_unique_words)\n",
    "        for action in action_probabilities:\n",
    "            action_probabilities[action] = action_probabilities[action]/self.num_training_rows\n",
    "        \n",
    "        for word in word_dict:\n",
    "            word_dict[word] = (word_dict[word]+self.smoothing_constant)/(word_counter+self.smoothing_constant*num_unique_words)\n",
    "        self.word_counter = word_counter\n",
    "        return (action_probabilities,action_dict,word_dict)\n",
    "    \n",
    "    def train(self):\n",
    "        text_command_and_action = self.training_data[self.columns]\n",
    "        (self.action_probabilities,self.action_dict,self.word_dict) = self.compute_probabilities(text_command_and_action)\n",
    "    \n",
    "    def predict(self,data):\n",
    "        num_unique_words = len(self.word_dict)\n",
    "        action_map = self.label_map\n",
    "        predictions = pd.DataFrame(columns=[self.columns[0], 'Predicted Action','Predicted Probabilities'])\n",
    "        stopwords = self.stopwords()\n",
    "        for i in list(data.index.values):\n",
    "            words = data.loc[i][0].lower().split()\n",
    "            action_probabilities = []\n",
    "            denominator = 0\n",
    "            for action in list(action_map.values()):\n",
    "                num_words = sum(list(self.action_dict[action].values()))\n",
    "                probability = 1\n",
    "                for word in words:\n",
    "                    if word not in stopwords:\n",
    "                        probability = probability * self.action_dict[action].get(word,(self.smoothing_constant)/(num_words+self.smoothing_constant*num_unique_words))\n",
    "                denominator += probability*self.action_probabilities[action]\n",
    "            for action in list(action_map.values()):\n",
    "                num_words = sum(list(self.action_dict[action].values()))\n",
    "                action_probability = self.action_probabilities[action]\n",
    "                probability = 1\n",
    "                for word in words:\n",
    "                    if word not in stopwords:\n",
    "                        probability = probability * self.action_dict[action].get(word,(self.smoothing_constant)/(num_words+self.smoothing_constant*num_unique_words))\n",
    "                        \n",
    "                probability = (probability * action_probability)/denominator\n",
    "    \n",
    "                \n",
    "                action_probabilities.append(probability)\n",
    "            predictions.loc[i]= [data.loc[i][0],action_map[action_probabilities.index(max(action_probabilities))],action_probabilities]\n",
    "        return predictions\n",
    "    def test(self):\n",
    "        action_map = self.label_map\n",
    "        correct = 0\n",
    "        preds = self.predict(self.testing_data)\n",
    "        actions = self.testing_data[self.columns[1]]\n",
    "        for i in list(self.testing_data.index.values):\n",
    "            if actions.loc[i][0] == preds['Predicted Action'].loc[i][0]:\n",
    "                correct += 1\n",
    "        losses = self.cross_entropy_loss(pd.concat([actions,preds['Predicted Probabilities']],axis=1))\n",
    "        accuracy = correct/self.num_testing_rows\n",
    "        return accuracy, losses, preds\n",
    "        \n",
    "    def softmax(self,labels):\n",
    "        softmax_labels = []\n",
    "        denominator = sum([math.exp(label) for label in labels])\n",
    "        for label in labels:\n",
    "            softmax_labels.append(math.exp(label)/denominator)\n",
    "        return softmax_labels\n",
    "    \n",
    "    def cross_entropy_loss(self,labels):\n",
    "        index_action = self.index_action\n",
    "        losses = dict()\n",
    "        for key in self.label_map:\n",
    "            losses[key] = []\n",
    "        for i in list(labels.index.values):\n",
    "            idx = index_action[labels.loc[i][0]]\n",
    "            loss = - math.log(labels.loc[i][1][idx])\n",
    "            losses[idx].append(loss)\n",
    "        for label in losses:\n",
    "            losses[label] = sum(losses[label])/len(losses[label])\n",
    "        return losses\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "0.8973209169054442\n",
      "[0.25792071298506464, 0.26536989597043403]\n"
     ]
    }
   ],
   "source": [
    "topic_accuracies = []\n",
    "cross_entropy_losses = [0,0]\n",
    "for i in range(100):\n",
    "    classifier = NaiveBayes(augmented_data,0.8,'topic',1)\n",
    "    classifier.train()\n",
    "    accuracy, losses, preds = classifier.test()\n",
    "    losses = list(losses.values())\n",
    "    topic_accuracies.append(accuracy)\n",
    "    cross_entropy_losses = [sum(x) for x in zip(cross_entropy_losses,losses)]\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "print(sum(topic_accuracies)/len(topic_accuracies))\n",
    "print([x/len(topic_accuracies) for x in cross_entropy_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "0.5969129287598949\n",
      "[2.065536718281523, 1.2081753466600305, 1.1558338185991048, 1.5290459803963214, 1.2461902320459644]\n"
     ]
    }
   ],
   "source": [
    "topic_accuracies = []\n",
    "cross_entropy_losses = [0,0,0,0,0]\n",
    "for i in range(100):\n",
    "    classifier = NaiveBayes(augmented_data,0.8,'task action',1)\n",
    "    classifier.train()\n",
    "    accuracy, losses, preds = classifier.test()\n",
    "    losses = list(losses.values())\n",
    "    topic_accuracies.append(accuracy)\n",
    "    cross_entropy_losses = [sum(x) for x in zip(cross_entropy_losses,losses)]\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "print(sum(topic_accuracies)/len(topic_accuracies))\n",
    "print([x/len(topic_accuracies) for x in cross_entropy_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "0.6427586206896551\n",
      "[1.8113355350334601, 0.9430479019411666, 1.067495212015915, 1.6394451040277886, 1.035731916757897]\n"
     ]
    }
   ],
   "source": [
    "topic_accuracies = []\n",
    "cross_entropy_losses = [0,0,0,0,0]\n",
    "for i in range(100):\n",
    "    classifier = NaiveBayes(augmented_data,0.8,'project action',1)\n",
    "    classifier.train()\n",
    "    accuracy, losses, preds = classifier.test()\n",
    "    losses = list(losses.values())\n",
    "    topic_accuracies.append(accuracy)\n",
    "    cross_entropy_losses = [sum(x) for x in zip(cross_entropy_losses,losses)]\n",
    "    if i%10 == 0:\n",
    "        print(i)\n",
    "print(sum(topic_accuracies)/len(topic_accuracies))\n",
    "print([x/len(topic_accuracies) for x in cross_entropy_losses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
