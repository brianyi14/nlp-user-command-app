{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modeler.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTI_C9o5Ce1_"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0ekH39jS38S"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import pandas as pd\n",
        "from gensim import models\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import optim\n",
        "from spellchecker import SpellChecker"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiEqONSSihF8"
      },
      "source": [
        "augmented_data = pd.read_csv('./drive/My Drive/Augmented_Data.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHRPtHXNLWJZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "9bb26b7d-60a9-46a5-cd9e-49096d6bfe7e"
      },
      "source": [
        "augmented_data[augmented_data['Topic']=='Project']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Command</th>\n",
              "      <th>Topic</th>\n",
              "      <th>Identifier</th>\n",
              "      <th>Action</th>\n",
              "      <th>One Hot Encoded Topic</th>\n",
              "      <th>One Hot Encoded Action</th>\n",
              "      <th>Verb/Noun</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>about Track trends on target projects</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>On Target</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,1,0,0,0]</td>\n",
              "      <td>BACKTRANSLATED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>throw Track trends on targets</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>On Target</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,1,0,0,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Track trends green project</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>Create</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[1,0,0,0,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>put Track trends project on target</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>On Target</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,1,0,0,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>as contrived Track trends project</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>On Target</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,1,0,0,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3104</th>\n",
              "      <td>move the study to completion</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>Completed</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,0,0,0,1]</td>\n",
              "      <td>BACKTRANSLATED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3107</th>\n",
              "      <td>Evaluate profit margins see complete</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>Completed</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,0,0,0,1]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3108</th>\n",
              "      <td>chance Evaluate profit margins</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>At Risk</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,0,1,0,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3109</th>\n",
              "      <td>Evaluate profit margins throw is danger</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>Danger</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[0,0,0,1,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3110</th>\n",
              "      <td>create a novel project study</td>\n",
              "      <td>Project</td>\n",
              "      <td>x</td>\n",
              "      <td>Create</td>\n",
              "      <td>[0,1]</td>\n",
              "      <td>[1,0,0,0,0]</td>\n",
              "      <td>SYNREPLACED</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1552 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Text Command  ...       Verb/Noun\n",
              "3       about Track trends on target projects  ...  BACKTRANSLATED\n",
              "4               throw Track trends on targets  ...     SYNREPLACED\n",
              "5                  Track trends green project  ...     SYNREPLACED\n",
              "6          put Track trends project on target  ...     SYNREPLACED\n",
              "7           as contrived Track trends project  ...     SYNREPLACED\n",
              "...                                       ...  ...             ...\n",
              "3104             move the study to completion  ...  BACKTRANSLATED\n",
              "3107     Evaluate profit margins see complete  ...     SYNREPLACED\n",
              "3108           chance Evaluate profit margins  ...     SYNREPLACED\n",
              "3109  Evaluate profit margins throw is danger  ...     SYNREPLACED\n",
              "3110             create a novel project study  ...     SYNREPLACED\n",
              "\n",
              "[1552 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0NPk5rJimb2"
      },
      "source": [
        "#load Google Word2Vec\n",
        "w = models.KeyedVectors.load_word2vec_format('./drive/My Drive/GoogleNews-vectors-negative300 (1).bin', binary=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_VuPLYsihs3"
      },
      "source": [
        "#words that will not be vectorized\n",
        "stopwords = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]  "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04UTYE1pirNJ"
      },
      "source": [
        "#function for cleaning sentence by removing grammmar \n",
        "def clean_sentence(sentence):\n",
        "  cleaned_sentence = ''\n",
        "  for char in sentence:\n",
        "    if char.isalpha() or char == ' ':\n",
        "      cleaned_sentence += char\n",
        "    if char == '-':\n",
        "      cleaned_sentence += ' '\n",
        "  return cleaned_sentence"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjGX6ZJLitnp"
      },
      "source": [
        "#function for transforming sentence into 2D numerical array \n",
        "def vectorize_sentence(sentence,vectorizer,max_len):\n",
        "  spell_checker = SpellChecker()\n",
        "  cleaned_sentence = clean_sentence(sentence)\n",
        "  sentence_lst = cleaned_sentence.split()\n",
        "  num_words = len(sentence_lst)\n",
        "  sentence_vector = np.zeros((max_len,300))\n",
        "  for i in range(num_words):\n",
        "    word = sentence_lst[i]\n",
        "    if word not in stopwords:\n",
        "      try:\n",
        "        vectorized_word = vectorizer.wv[word]\n",
        "      except KeyError:\n",
        "        misspelled = spell_checker.unknown([word])\n",
        "        corrected_word = None\n",
        "        for word in misspelled:\n",
        "          corrected_word = spell_checker.correction(word)\n",
        "        try:\n",
        "          vectorized_word = vectorizer.wv[corrected_word]\n",
        "        except KeyError:\n",
        "          vectorized_word = np.zeros(300)\n",
        "    else:\n",
        "      #stop word is empty vector of 0s\n",
        "      vectorized_word = np.zeros(300)\n",
        "    sentence_vector[i] = vectorized_word\n",
        "  for j in range(num_words,max_len,1):\n",
        "    sentence_vector[j] = np.zeros(300)\n",
        "  return sentence_vector"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCz-pbIMjb8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef6aaa03-df0d-4f48-9ffd-83921eebd579"
      },
      "source": [
        "print(torch.tensor(vectorize_sentence('Done with project data cleaning',w,10)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0654,  0.2305, -0.2891,  ..., -0.2715, -0.0043,  0.1611],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0181,  0.0085,  0.0698,  ..., -0.1250, -0.0562, -0.1084],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQULMiY2iyBb"
      },
      "source": [
        "#function for changing pandas dataframe from sentences to 2D numerical array\n",
        "def vectorize_dataset(df, column, filter=None):\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "  if filter != None:\n",
        "    df = df.loc[df['Topic'] == filter]\n",
        "  text_commands = df['Text Command']\n",
        "  num_rows = len(df.index)\n",
        "  max_len = max([len(text_commands.loc[i].split()) for i in df.index.values])\n",
        "  data_vector = np.zeros((num_rows,max_len,300))\n",
        "  idx = 0\n",
        "  for i in df.index.values:\n",
        "    sentence = df.loc[i][0]\n",
        "    vectorized_sentence = vectorize_sentence(sentence,w,max_len) \n",
        "    data_vector[idx] = vectorized_sentence\n",
        "    idx += 1\n",
        "  return data_vector, df[column], max_len, text_commands"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frAB-G2wQdFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0abbc27e-d94c-4a12-c404-ddebd11f5823"
      },
      "source": [
        "#load all the data and labels associated with the different use cases\n",
        "topic_data, topic_labels, topic_max_len, topic_text_commands = vectorize_dataset(augmented_data, 'One Hot Encoded Topic')\n",
        "task_action_data, task_action_labels, task_action_max_len, task_action_text_commands = vectorize_dataset(augmented_data, 'One Hot Encoded Action', 'Task')\n",
        "project_action_data, project_action_labels, project_action_max_len, project_action_text_commands = vectorize_dataset(augmented_data, 'One Hot Encoded Action', 'Project')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkXKk_f_BRXB"
      },
      "source": [
        "#function for converting the data represented by numpy arrays into tensors\n",
        "def data_to_tensor(labels,data,array_size):\n",
        "  labels_tensor = np.zeros((len(labels.index),array_size))\n",
        "  idx = 0\n",
        "  for i in (labels.index.values):\n",
        "    labels_tensor[idx] = np.fromstring(labels.loc[i][1:-1], dtype=np.float64, sep=',') \n",
        "    idx += 1\n",
        "  data_tensor = torch.tensor(data)\n",
        "  labels_tensor = torch.tensor(labels_tensor)\n",
        "  return labels_tensor, data_tensor"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tTukgpEEo7e"
      },
      "source": [
        "#convert all the data into tensor format \n",
        "topic_labels, topic_data = data_to_tensor(topic_labels,topic_data,2)\n",
        "task_action_labels, task_action_data = data_to_tensor(task_action_labels,task_action_data,5)\n",
        "project_action_labels, project_action_data = data_to_tensor(project_action_labels, project_action_data,5)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ki5pArx7TBUE"
      },
      "source": [
        "#LSTM architecture that takes input of vectorized sentences and outputs probability for each topic\n",
        "class TopicModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(TopicModel,self).__init__()\n",
        "    self.lstm = nn.LSTM(300,100,batch_first = True)\n",
        "    \"\"\"Change the second parameter according to whether topic or project and task are being trained. 2 is for topic, 5 is for project/task\"\"\"\n",
        "    self.outputtopic = nn.Linear(100,5)\n",
        "    self.softmax = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "  def forward(self,x):\n",
        "    output, (h_n,c_n) = self.lstm(x)\n",
        "    outputt = self.outputtopic(h_n)\n",
        "    prob_output = self.softmax(outputt)\n",
        "    return prob_output\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8G1LsToZw4w"
      },
      "source": [
        "#set feature size of hidden units\n",
        "hidden_size = 100\n",
        "\n",
        "#feature dimension of Google Word2Vec word vector(default is 300)\n",
        "input_size = 300\n",
        "\"\"\"Change this number according to whether topic or project and task are being trained. 2 is for topic, 5 is for project/task\"\"\"\n",
        "#number of topics to predict\n",
        "num_topics = 5\n",
        "\n",
        "#set learning rate \n",
        "lr = .1\n",
        "\n",
        "#set training loss metric\n",
        "loss_metric = nn.NLLLoss()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAQ4k_0vpGQ0"
      },
      "source": [
        "topic_text_commands,topic_text_commands_raw_text = topic_data, topic_text_commands\n",
        "project_action_text_commands,project_action_text_commands_raw_text = project_action_data, project_action_text_commands\n",
        "task_action_text_commands,task_action_text_commands_raw_text = task_action_data, task_action_text_commands\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp_Oz8mZC0t_"
      },
      "source": [
        "def train(topic_tensor, text_command_tensor):\n",
        "    model.train()\n",
        "    #reset the model gradients to 0\n",
        "    model.zero_grad()\n",
        "    #predicted label from model\n",
        "    output = model(text_command_tensor.float())[0]\n",
        "    idxs = torch.argmax(topic_tensor,dim=-1)\n",
        "    #calculate negative log likelihood loss from batch of data \n",
        "    loss = loss_metric(output, idxs)\n",
        "    #backpropogate through the model based on NLL loss\n",
        "    loss.backward()\n",
        "    #update model parameters using gradients \n",
        "    optimizer.step()\n",
        "    \n",
        "\n",
        "    return output, loss.item()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Px2RUnzbEL"
      },
      "source": [
        "#function for testing model on batch of data\n",
        "def test(model, topic_tensor, text_command_tensor):\n",
        "  model.eval()\n",
        "  num_labels = len(topic_tensor[0])\n",
        "  preds = model(text_command_tensor.float())[0]\n",
        "  idxs = torch.argmax(topic_tensor[0],dim=-1)\n",
        "  loss = loss_metric(preds, idxs)\n",
        "  correct = 0\n",
        "  for i in range(num_labels):\n",
        "    pred = preds[i]\n",
        "    pred_idx = torch.argmax(pred)\n",
        "    label = topic_tensor[0][i]\n",
        "    label_idx = torch.argmax(label)\n",
        "    if pred_idx == label_idx:\n",
        "      correct += 1\n",
        "  return ((correct/num_labels), loss)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL2aPOiFey9Y"
      },
      "source": [
        "def predict(model, text_input, wordvec,label2pred):\n",
        "  model.eval()\n",
        "  vectorized_sentence = vectorize_sentence(text_input,wordvec,10)\n",
        "  sentence_tensor = torch.tensor(vectorized_sentence)\n",
        "  batch_sentence_tensor = torch.unsqueeze(sentence_tensor,0)\n",
        "  pred = model(batch_sentence_tensor.float())\n",
        "  return label2pred[int(torch.argmax(pred,dim=-1))]\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0qHMGo8lIpO"
      },
      "source": [
        "#Training topic\n",
        "epochs = 80\n",
        "#set batch size \n",
        "batch_size = 40\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "testing_losses = []\n",
        "testing_accuracies = []\n",
        "testing_losses = []\n",
        "for i in range(1):\n",
        "  current_loss = 0\n",
        "  all_losses = []\n",
        "  model = TopicModel()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  idxs = torch.randperm(len(topic_text_commands))\n",
        "  text_commands = topic_text_commands[idxs]\n",
        "  labels = topic_labels[idxs]\n",
        "\n",
        "  training_text_commands,testing_text_commands = text_commands[:4080], text_commands[4080:5100]\n",
        "  training_labels, testing_labels = labels[:4080], labels[4080:5100]\n",
        "\n",
        "  #set number of batches\n",
        "  training_num_batches = int(len(training_text_commands)/batch_size) \n",
        "\n",
        "  #reshape text commands and labels to fit training\n",
        "  training_text_commands = torch.reshape(training_text_commands,(training_num_batches,batch_size,topic_max_len,300))\n",
        "  training_labels = torch.reshape(training_labels,(training_num_batches,batch_size,num_topics))\n",
        "  testing_labels = torch.reshape(testing_labels,(1,testing_labels.shape[0],testing_labels.shape[1]))\n",
        "\n",
        "  for iter in range(1, epochs + 1):\n",
        "    for batch_iter in range(training_num_batches):\n",
        "      text_batch, label_batch = training_text_commands[batch_iter], training_labels[batch_iter]\n",
        "      output, loss = train(label_batch, text_batch)\n",
        "      current_loss += loss\n",
        "\n",
        "    # Print iter number, loss, name and guess\n",
        "    #if iter % print_every == 0:\n",
        "        #guess, guess_i = categoryFromOutput(output)\n",
        "        #correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        #print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter == epochs:\n",
        "      testing_accuracy, testing_loss = test(model, testing_labels, testing_text_commands)\n",
        "      testing_accuracies.append(testing_accuracy)\n",
        "      testing_losses.append(testing_loss.item())\n",
        "      all_losses.append(current_loss / training_num_batches)\n",
        "    current_loss = 0"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnyNS8dplIYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7358789-6884-426f-96be-f2140e11f13c"
      },
      "source": [
        "sum(testing_accuracies)/len(testing_accuracies)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.964516129032258"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cabiEtEvaKqA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0aff998-343c-461a-dba1-8dfca9c6eb7d"
      },
      "source": [
        "sum(testing_losses)/len(testing_losses)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09676515311002731"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "is6mkDqWiPnu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc30b3c-8a20-4cc8-d070-976962d0d565"
      },
      "source": [
        "print(predict(project_action_model,'Finished with project data cleaning',w,{0: 'Create',1: 'On Target',2: 'At Risk',3: 'Danger',4: 'Completed'}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rv_Lzt8BPVB"
      },
      "source": [
        "#Training project action\n",
        "epochs = 80\n",
        "#set batch size \n",
        "batch_size = 40\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "testing_losses = []\n",
        "testing_accuracies = []\n",
        "testing_losses = []\n",
        "for i in range(1):\n",
        "  current_loss = 0\n",
        "  all_losses = []\n",
        "  model = TopicModel()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  idxs = torch.randperm(len(project_action_text_commands))\n",
        "  text_commands = project_action_text_commands[idxs]\n",
        "  labels = project_action_labels[idxs]\n",
        "\n",
        "  training_text_commands,testing_text_commands = text_commands[:2040], text_commands[2040:2550]\n",
        "  training_labels, testing_labels = labels[:2040], labels[2040:2550]\n",
        "\n",
        "  #set number of batches\n",
        "  training_num_batches = int(len(training_text_commands)/batch_size) \n",
        "\n",
        "  #reshape text commands and labels to fit training\n",
        "  training_text_commands = torch.reshape(training_text_commands,(training_num_batches,batch_size,project_action_max_len,300))\n",
        "  training_labels = torch.reshape(training_labels,(training_num_batches,batch_size,num_topics))\n",
        "  testing_labels = torch.reshape(testing_labels,(1,testing_labels.shape[0],testing_labels.shape[1]))\n",
        "\n",
        "  for iter in range(1, epochs + 1):\n",
        "    for batch_iter in range(training_num_batches):\n",
        "      text_batch, label_batch = training_text_commands[batch_iter], training_labels[batch_iter]\n",
        "      output, loss = train(label_batch, text_batch)\n",
        "      current_loss += loss\n",
        "\n",
        "    # Print iter number, loss, name and guess\n",
        "    #if iter % print_every == 0:\n",
        "        #guess, guess_i = categoryFromOutput(output)\n",
        "        #correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        #print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter == epochs:\n",
        "      testing_accuracy, testing_loss = test(model, testing_labels, testing_text_commands)\n",
        "      testing_accuracies.append(testing_accuracy)\n",
        "      testing_losses.append(testing_loss.item())\n",
        "      all_losses.append(current_loss / training_num_batches)\n",
        "    current_loss = 0"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT7zkiENBxbH",
        "outputId": "9f7a2560-31a5-42aa-f567-5a517d1a0144"
      },
      "source": [
        "sum(testing_accuracies)/len(testing_accuracies)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.89"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "La2Q7nDdByCn",
        "outputId": "ffa8b272-a9eb-4ae9-92d0-516c03346845"
      },
      "source": [
        "sum(testing_losses)/len(testing_losses)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.28429391980171204"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z0WhKEECT_0"
      },
      "source": [
        "#Training task action\n",
        "epochs = 80\n",
        "#set batch size \n",
        "batch_size = 40\n",
        "\n",
        "# Keep track of losses for plotting\n",
        "testing_losses = []\n",
        "testing_accuracies = []\n",
        "testing_losses = []\n",
        "for i in range(1):\n",
        "  current_loss = 0\n",
        "  all_losses = []\n",
        "  model = TopicModel()\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "  idxs = torch.randperm(len(task_action_text_commands))\n",
        "  text_commands = task_action_text_commands[idxs]\n",
        "  labels = task_action_labels[idxs]\n",
        "\n",
        "  training_text_commands,testing_text_commands = text_commands[:2040], text_commands[2040:2550]\n",
        "  training_labels, testing_labels = labels[:2040], labels[2040:2550]\n",
        "\n",
        "  #set number of batches\n",
        "  training_num_batches = int(len(training_text_commands)/batch_size) \n",
        "\n",
        "  #reshape text commands and labels to fit training\n",
        "  training_text_commands = torch.reshape(training_text_commands,(training_num_batches,batch_size,task_action_max_len,300))\n",
        "  training_labels = torch.reshape(training_labels,(training_num_batches,batch_size,num_topics))\n",
        "  testing_labels = torch.reshape(testing_labels,(1,testing_labels.shape[0],testing_labels.shape[1]))\n",
        "\n",
        "  for iter in range(1, epochs + 1):\n",
        "    for batch_iter in range(training_num_batches):\n",
        "      text_batch, label_batch = training_text_commands[batch_iter], training_labels[batch_iter]\n",
        "      output, loss = train(label_batch, text_batch)\n",
        "      current_loss += loss\n",
        "\n",
        "    # Print iter number, loss, name and guess\n",
        "    #if iter % print_every == 0:\n",
        "        #guess, guess_i = categoryFromOutput(output)\n",
        "        #correct = '✓' if guess == category else '✗ (%s)' % category\n",
        "        #print('%d %d%% (%s) %.4f %s / %s %s' % (iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n",
        "\n",
        "    # Add current loss avg to list of losses\n",
        "    if iter == epochs:\n",
        "      testing_accuracy, testing_loss = test(model, testing_labels, testing_text_commands)\n",
        "      testing_accuracies.append(testing_accuracy)\n",
        "      testing_losses.append(testing_loss.item())\n",
        "      all_losses.append(current_loss / training_num_batches)\n",
        "    current_loss = 0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjYcvr2MCbON",
        "outputId": "df8672de-3445-4fe8-a387-c04cb042718f"
      },
      "source": [
        "sum(testing_accuracies)/len(testing_accuracies)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9766666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1CMLJASCb16",
        "outputId": "17dbfb65-b166-4402-dcb8-a824d009d3d4"
      },
      "source": [
        "sum(testing_losses)/len(testing_losses)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.08044631034135818"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}